{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:17.699412Z",
     "start_time": "2024-11-07T20:18:12.219166Z"
    }
   },
   "source": [
    "from metrics import WordLength, WordExact\n",
    "\n",
    "import os\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchmetrics import MeanMetric\n",
    "from torchmetrics.text import EditDistance\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, DataCollatorWithPadding\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:17.702471Z",
     "start_time": "2024-11-07T20:18:17.700432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "eval_steps = 200\n",
    "learning_rate = 1e-4\n",
    "checkpoint = \"t5-small\"\n",
    "run_name = \"test\"\n",
    "run_dir = os.path.join(\"runs\", run_name)"
   ],
   "id": "5ec991a8899c64fe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:18.688524Z",
     "start_time": "2024-11-07T20:18:17.703127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "writer = SummaryWriter(log_dir=os.path.join(run_dir, \"logs\"))\n",
    "os.makedirs(os.path.join(run_dir, \"checkpoints\"), exist_ok=True)"
   ],
   "id": "96b53181b933b920",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:18.691711Z",
     "start_time": "2024-11-07T20:18:18.689219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    inputs = tokenizer(example[\"clue\"], truncation=True, max_length=96, padding=\"max_length\")\n",
    "    targets = tokenizer(example[\"answer\"], truncation=True, max_length=32, padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": inputs.input_ids,\n",
    "        \"attention_mask\": inputs.attention_mask,\n",
    "        \"labels\": targets.input_ids\n",
    "    }"
   ],
   "id": "c24a5dca0aafc55a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.526714Z",
     "start_time": "2024-11-07T20:18:18.693713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(pd.read_csv(\"data/train.csv\")),\n",
    "        \"eval\": Dataset.from_pandas(pd.read_csv(\"data/eval.csv\").iloc[:1000]),\n",
    "    }\n",
    ")\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"clue\", \"answer\"])\n",
    "tokenized_datasets.set_format(\"torch\")"
   ],
   "id": "bc35dec7e2420a45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/433821 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5748988b20a64b808716ced17b3ffb38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "181b02fd53554c43bd0aabced93431dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.529387Z",
     "start_time": "2024-11-07T20:18:42.527413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"eval\"], batch_size=batch_size)"
   ],
   "id": "bb860c18c78e4bda",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.532053Z",
     "start_time": "2024-11-07T20:18:42.530023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_checkpoint(step, model, optimizer, scheduler, best_val_loss, checkpoint_dir=\"checkpoints\", filename=\"checkpoint.pth\"):\n",
    "    checkpoint_path = os.path.join(run_dir, checkpoint_dir, filename)\n",
    "    torch.save({\n",
    "        'epoch': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),  # Save scheduler state\n",
    "        'best_val_loss': best_val_loss\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")"
   ],
   "id": "e6ac40e9263109ee",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.534869Z",
     "start_time": "2024-11-07T20:18:42.532926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_output(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return predictions, labels"
   ],
   "id": "743b976d7c93821",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.539840Z",
     "start_time": "2024-11-07T20:18:42.535718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loss_metric = MeanMetric()\n",
    "eval_loss_metric = MeanMetric()\n",
    "train_exact_metric = WordExact()\n",
    "eval_exact_metric = WordExact()\n",
    "train_length_metric = WordLength()\n",
    "eval_length_metric = WordLength()\n",
    "train_edit_metric = EditDistance()\n",
    "eval_edit_metric = EditDistance()"
   ],
   "id": "6bea88b09d962fc6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.543385Z",
     "start_time": "2024-11-07T20:18:42.540523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate():\n",
    "    eval_loss_metric.reset()\n",
    "    eval_length_metric.reset()\n",
    "    eval_exact_metric.reset()\n",
    "    eval_edit_metric.reset()\n",
    "    \n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        predictions, labels = decode_output(outputs[1], batch[\"labels\"])\n",
    "\n",
    "        eval_loss_metric.update(loss.item(), batch[\"input_ids\"].size(0))\n",
    "        eval_length_metric.update(predictions, labels)\n",
    "        eval_exact_metric.update(predictions, labels)\n",
    "        eval_edit_metric.update(predictions, labels)\n",
    "\n",
    "    metrics = {\n",
    "        \"eval/loss\": eval_loss_metric.compute(),\n",
    "        \"eval/length\": eval_length_metric.compute(),\n",
    "        \"eval/exact\": eval_exact_metric.compute(),\n",
    "        \"eval/edit\": eval_edit_metric.compute(),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "id": "7f15ed6a92e964fb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:18:42.757039Z",
     "start_time": "2024-11-07T20:18:42.544106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(num_training_steps * 0.1),\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ],
   "id": "4bca8872d5046496",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:19:05.348204Z",
     "start_time": "2024-11-07T20:18:42.757700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "step = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch in tqdm(train_dataloader, leave=False):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "        if (step + 1) % eval_steps == 0:\n",
    "            eval_metrics = evaluate()\n",
    "    \n",
    "            for key, value in eval_metrics.items():\n",
    "                writer.add_scalar(key, value, step)\n",
    "                \n",
    "            if eval_metrics[\"eval/loss\"] < best_val_loss:\n",
    "                best_val_loss = eval_metrics[\"eval/loss\"]\n",
    "                save_checkpoint(step, model, optimizer, scheduler, best_val_loss)\n",
    "    \n",
    "        model.train()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "    \n",
    "        train_loss_metric.reset()\n",
    "        train_length_metric.reset()\n",
    "        train_edit_metric.reset()\n",
    "        train_exact_metric.reset()\n",
    "    \n",
    "        predictions, labels = decode_output(outputs[1], batch[\"labels\"])\n",
    "        train_loss_metric.update(loss.item(), batch[\"input_ids\"].size(0))\n",
    "        train_length_metric.update(predictions, labels)\n",
    "        train_edit_metric.update(predictions, labels)\n",
    "        train_exact_metric.update(predictions, labels)\n",
    "    \n",
    "        writer.add_scalar(\"train/loss\", loss.item(), step)\n",
    "        writer.add_scalar(\"train/length\", train_length_metric.compute(), step)\n",
    "        writer.add_scalar(\"train/exact\", train_exact_metric.compute(), step)\n",
    "        writer.add_scalar(\"train/edit\", train_edit_metric.compute(), step)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        writer.add_scalar(\"learning_rate\", current_lr, step)\n",
    "    \n",
    "        scheduler.step()\n",
    "        step += 1\n",
    "\n",
    "writer.close()"
   ],
   "id": "a1bbc99a81331227",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b84e1dc3d3e408e81ee1e33493aec28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/13557 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6d6806c03d54bc08bf529238eef6718"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m train_edit_metric\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m     25\u001B[0m train_exact_metric\u001B[38;5;241m.\u001B[39mreset()\n\u001B[0;32m---> 27\u001B[0m predictions, labels \u001B[38;5;241m=\u001B[39m \u001B[43mdecode_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlabels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m train_loss_metric\u001B[38;5;241m.\u001B[39mupdate(loss\u001B[38;5;241m.\u001B[39mitem(), batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m     29\u001B[0m train_length_metric\u001B[38;5;241m.\u001B[39mupdate(predictions, labels)\n",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m, in \u001B[0;36mdecode_output\u001B[0;34m(logits, labels)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_output\u001B[39m(logits, labels):\n\u001B[1;32m      2\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(logits, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     labels \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mbatch_decode(labels, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predictions, labels\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3964\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.batch_decode\u001B[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[1;32m   3940\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbatch_decode\u001B[39m(\n\u001B[1;32m   3941\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3942\u001B[0m     sequences: Union[List[\u001B[38;5;28mint\u001B[39m], List[List[\u001B[38;5;28mint\u001B[39m]], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp.ndarray\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.Tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.Tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3945\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3946\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m   3947\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3948\u001B[0m \u001B[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001B[39;00m\n\u001B[1;32m   3949\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3962\u001B[0m \u001B[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001B[39;00m\n\u001B[1;32m   3963\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3964\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\n\u001B[1;32m   3965\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3966\u001B[0m \u001B[43m            \u001B[49m\u001B[43mseq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3967\u001B[0m \u001B[43m            \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3968\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3969\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3970\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3971\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mseq\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msequences\u001B[49m\n\u001B[1;32m   3972\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3965\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   3940\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbatch_decode\u001B[39m(\n\u001B[1;32m   3941\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3942\u001B[0m     sequences: Union[List[\u001B[38;5;28mint\u001B[39m], List[List[\u001B[38;5;28mint\u001B[39m]], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp.ndarray\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.Tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf.Tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3945\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3946\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m   3947\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3948\u001B[0m \u001B[38;5;124;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001B[39;00m\n\u001B[1;32m   3949\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3962\u001B[0m \u001B[38;5;124;03m        `List[str]`: The list of decoded sentences.\u001B[39;00m\n\u001B[1;32m   3963\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   3964\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m-> 3965\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3966\u001B[0m \u001B[43m            \u001B[49m\u001B[43mseq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3967\u001B[0m \u001B[43m            \u001B[49m\u001B[43mskip_special_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_special_tokens\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3968\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclean_up_tokenization_spaces\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3969\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3970\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3971\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m seq \u001B[38;5;129;01min\u001B[39;00m sequences\n\u001B[1;32m   3972\u001B[0m     ]\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:4002\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.decode\u001B[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001B[0m\n\u001B[1;32m   3981\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3982\u001B[0m \u001B[38;5;124;03mConverts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001B[39;00m\n\u001B[1;32m   3983\u001B[0m \u001B[38;5;124;03mtokens and clean up tokenization spaces.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3999\u001B[0m \u001B[38;5;124;03m    `str`: The decoded sentence.\u001B[39;00m\n\u001B[1;32m   4000\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4001\u001B[0m \u001B[38;5;66;03m# Convert inputs to python lists\u001B[39;00m\n\u001B[0;32m-> 4002\u001B[0m token_ids \u001B[38;5;241m=\u001B[39m \u001B[43mto_py_obj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4004\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decode(\n\u001B[1;32m   4005\u001B[0m     token_ids\u001B[38;5;241m=\u001B[39mtoken_ids,\n\u001B[1;32m   4006\u001B[0m     skip_special_tokens\u001B[38;5;241m=\u001B[39mskip_special_tokens,\n\u001B[1;32m   4007\u001B[0m     clean_up_tokenization_spaces\u001B[38;5;241m=\u001B[39mclean_up_tokenization_spaces,\n\u001B[1;32m   4008\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4009\u001B[0m )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:275\u001B[0m, in \u001B[0;36mto_py_obj\u001B[0;34m(obj)\u001B[0m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m framework, test_func \u001B[38;5;129;01min\u001B[39;00m framework_to_test_func\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m test_func(obj):\n\u001B[0;32m--> 275\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mframework_to_py_obj\u001B[49m\u001B[43m[\u001B[49m\u001B[43mframework\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;66;03m# tolist also works on 0d np arrays\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, np\u001B[38;5;241m.\u001B[39mnumber):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/generic.py:260\u001B[0m, in \u001B[0;36mto_py_obj.<locals>.<lambda>\u001B[0;34m(obj)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mto_py_obj\u001B[39m(obj):\n\u001B[1;32m    255\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;124;03m    Convert a TensorFlow tensor, PyTorch tensor, Numpy array or python list to a python list.\u001B[39;00m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     framework_to_py_obj \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m--> 260\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m    262\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjax\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: np\u001B[38;5;241m.\u001B[39masarray(obj)\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m    263\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnp\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m obj: obj\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m    264\u001B[0m     }\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, (\u001B[38;5;28mdict\u001B[39m, UserDict)):\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {k: to_py_obj(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mitems()}\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
